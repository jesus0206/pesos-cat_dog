{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesus_tn79/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing import image\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2048 images belonging to 2 classes.\n",
      "Found 832 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width = 150\n",
    "img_height = 150\n",
    "train_data_dir = 'data/train'\n",
    "valid_data_dir = 'data/validation'\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(directory=train_data_dir,\n",
    "                                              target_size=(img_width,img_height),\n",
    "                                              classes=['dogs','cats'],\n",
    "                                              class_mode='binary',\n",
    "                                              batch_size=16)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(directory=valid_data_dir,\n",
    "                                                   target_size=(img_width,img_height),\n",
    "                                                   classes=['dogs','cats'],\n",
    "                                                   class_mode='binary',\n",
    "                                                   batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jesus_tn79/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jesus_tn79/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "model complied!!\n",
      "starting training....\n",
      "WARNING:tensorflow:From /home/jesus_tn79/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "128/128 [==============================] - 44s 346ms/step - loss: 0.7167 - acc: 0.5259 - val_loss: 0.6796 - val_acc: 0.6466\n",
      "Epoch 2/20\n",
      "128/128 [==============================] - 40s 316ms/step - loss: 0.6666 - acc: 0.5996 - val_loss: 0.6426 - val_acc: 0.6839\n",
      "Epoch 3/20\n",
      "128/128 [==============================] - 41s 321ms/step - loss: 0.6410 - acc: 0.6577 - val_loss: 0.6439 - val_acc: 0.6298\n",
      "Epoch 4/20\n",
      "128/128 [==============================] - 40s 315ms/step - loss: 0.5930 - acc: 0.6963 - val_loss: 0.5664 - val_acc: 0.7175\n",
      "Epoch 5/20\n",
      "128/128 [==============================] - 40s 315ms/step - loss: 0.5505 - acc: 0.7227 - val_loss: 0.5779 - val_acc: 0.6983\n",
      "Epoch 6/20\n",
      "128/128 [==============================] - 40s 315ms/step - loss: 0.5203 - acc: 0.7510 - val_loss: 0.5903 - val_acc: 0.6899\n",
      "Epoch 7/20\n",
      "128/128 [==============================] - 40s 313ms/step - loss: 0.4868 - acc: 0.7773 - val_loss: 0.5574 - val_acc: 0.7043\n",
      "Epoch 8/20\n",
      "128/128 [==============================] - 40s 314ms/step - loss: 0.4318 - acc: 0.8086 - val_loss: 0.6100 - val_acc: 0.6827\n",
      "Epoch 9/20\n",
      "128/128 [==============================] - 40s 314ms/step - loss: 0.4117 - acc: 0.8062 - val_loss: 0.5822 - val_acc: 0.7019\n",
      "Epoch 10/20\n",
      "128/128 [==============================] - 40s 314ms/step - loss: 0.3669 - acc: 0.8403 - val_loss: 0.5788 - val_acc: 0.7440\n",
      "Epoch 11/20\n",
      "128/128 [==============================] - 41s 319ms/step - loss: 0.3295 - acc: 0.8667 - val_loss: 0.7002 - val_acc: 0.7284\n",
      "Epoch 12/20\n",
      "128/128 [==============================] - 40s 314ms/step - loss: 0.2914 - acc: 0.8848 - val_loss: 0.6396 - val_acc: 0.7476\n",
      "Epoch 13/20\n",
      "128/128 [==============================] - 41s 317ms/step - loss: 0.2392 - acc: 0.9048 - val_loss: 0.8546 - val_acc: 0.7380\n",
      "Epoch 14/20\n",
      "128/128 [==============================] - 40s 314ms/step - loss: 0.2255 - acc: 0.9087 - val_loss: 0.8266 - val_acc: 0.7236\n",
      "Epoch 15/20\n",
      "128/128 [==============================] - 40s 313ms/step - loss: 0.2109 - acc: 0.9189 - val_loss: 0.8651 - val_acc: 0.7091\n",
      "Epoch 16/20\n",
      "128/128 [==============================] - 40s 314ms/step - loss: 0.1719 - acc: 0.9331 - val_loss: 0.8993 - val_acc: 0.7272\n",
      "Epoch 17/20\n",
      "128/128 [==============================] - 40s 316ms/step - loss: 0.1598 - acc: 0.9502 - val_loss: 1.0895 - val_acc: 0.7188\n",
      "Epoch 18/20\n",
      "128/128 [==============================] - 40s 315ms/step - loss: 0.1443 - acc: 0.9468 - val_loss: 1.1608 - val_acc: 0.7091\n",
      "Epoch 19/20\n",
      "128/128 [==============================] - 41s 317ms/step - loss: 0.1544 - acc: 0.9512 - val_loss: 1.0516 - val_acc: 0.7127\n",
      "Epoch 20/20\n",
      "128/128 [==============================] - 40s 315ms/step - loss: 0.1451 - acc: 0.9507 - val_loss: 0.9665 - val_acc: 0.7284\n",
      "training finished!!\n",
      "saving weights to simple_CNN.h5\n",
      "all weights saved successfully !!\n"
     ]
    }
   ],
   "source": [
    "model =Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3), input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3), input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('model complied!!')\n",
    "\n",
    "print('starting training....')\n",
    "training = model.fit_generator(generator=train_generator,\n",
    "                               steps_per_epoch=2048 // 16,\n",
    "                               epochs=20,\n",
    "                               validation_data=validation_generator,\n",
    "                               validation_steps=832//16)\n",
    "\n",
    "print('training finished!!')\n",
    "\n",
    "print('saving weights to simple_CNN.h5')\n",
    "\n",
    "model.save_weights('./models/simple_CNN.h5')\n",
    "\n",
    "print('all weights saved successfully !!')\n",
    "#models.load_weights('models/simple_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fbd0e7d8e10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot create group in read only mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1d7160f752ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/simple_CNN.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# training_set.class_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot create group in read only mode.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot create group in read only mode."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "\n",
    "test_image = image.load_img('data/validation/dogs/dog.1150.jpg', target_size=(150, 150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "model=load_model('model/simple_CNN.h5')\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "if result[0][0] == 1: \n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction+\" \"+str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
